Instalar Ollama:

> brew install ollama

Inicia el servicio:

> ollama serve

Descargar un modelo pequeÃ±o:

> ollama pull llama3.2
> ollama run llama3.2
> ollama list
> ollama rm <modelo>

Verificar endpoint:

> http://localhost:11434 

Test rapido:

> curl http://localhost:11434 


